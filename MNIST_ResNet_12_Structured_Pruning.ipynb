{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrcEK6PCaTYA",
        "outputId": "c2bc2d09-04a3-4973-a453-49582bf21001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: flwr_datasets[vision] in /home/vaishnavi/.local/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: datasets<2.20.0,>=2.14.6 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (2.19.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (1.26.4)\n",
            "Requirement already satisfied: seaborn<0.14.0,>=0.13.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (0.13.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (4.66.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.5 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (3.9.1)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from flwr_datasets[vision]) (10.4.0)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2024.3.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (0.6)\n",
            "Requirement already satisfied: multiprocess in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (0.70.16)\n",
            "Requirement already satisfied: xxhash in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (3.4.1)\n",
            "Requirement already satisfied: aiohttp in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (3.9.5)\n",
            "Requirement already satisfied: requests>=2.32.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (3.6.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (0.3.8)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (21.3)\n",
            "Requirement already satisfied: pandas in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (0.24.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (17.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (1.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/vaishnavi/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/vaishnavi/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (2.9.0.post0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (4.53.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vaishnavi/.local/lib/python3.10/site-packages (from aiohttp->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (6.0.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vaishnavi/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (4.12.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/vaishnavi/.local/lib/python3.10/site-packages (from pandas->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.5->flwr_datasets[vision]) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (2020.6.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vaishnavi/.local/lib/python3.10/site-packages (from requests>=2.32.1->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (1.26.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets<2.20.0,>=2.14.6->flwr_datasets[vision]) (3.3)\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg8kmgAuaTYA"
      },
      "source": [
        "We will be using the _simulation_ mode in Flower, which allows you to run a large number of clients without the overheads of manually managing devices. This is achieved via the [Virtual Client Engine](https://flower.ai/docs/framework/how-to-run-simulations.html) in Flower. With simulation, you can dynamically scale your experiments whether you run the code on your laptop, a machine with a single GPU, a server with multiple GPUs os even on a cluster with multiple servers. The `Virtual Client Engine` handles everything transparently and it allows you to specify how many resources (e.g. CPU cores, GPU VRAM) should be assigned to each virtual client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Cpvms8aTYA"
      },
      "source": [
        "\n",
        "Flower is agnostic to your choice of ML Framework. Flower works with `PyTorch`, `Tensorflow`, `NumPy`, `ðŸ¤— Transformers`, `MXNet`, `JAX`, `scikit-learn`, `fastai`, `Pandas`. Flower also supports all major platforms: `iOS`, `Android` and plain `C++`. You can find a _quickstart-_ example for each of the above in the [Flower Repository](https://github.com/adap/flower/tree/main/examples) inside the `examples/` directory.\n",
        "\n",
        "In this tutorial we are going to use PyTorch, it comes pre-installed in your Collab runtime so there is no need to installed it again. If you wouuld like to install another version, you can still do that in the same way other packages are installed via `!pip`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6yThh8saTYB"
      },
      "source": [
        "We are going to install some other dependencies you are likely familiar with. Let's install `maplotlib` to plot our results at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lho9g6-OaTYB"
      },
      "source": [
        "# Preparing the experiment\n",
        "\n",
        "This tutorial is not so much about novel architectural designs so we keep things simple and make use of a typical CNN that is adequate for the MNIST image classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zu3bXdKJaTYB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet12(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet12, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)  # Change input channels from 3 to 1\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(64, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(128, 3, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 3, stride=2)\n",
        "        self.layer4 = self._make_layer(512, 3, stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcqBEnfwaTYB"
      },
      "source": [
        "We'll be training the model in a Federated setting. In order to do that, we need to define two functions:\n",
        "\n",
        "* `train()` that will train the model given a dataloader.\n",
        "* `test()` that will be used to evaluate the performance of the model on held-out data, e.g., a training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iT-OgTmfaTYC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vaishnavi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2024-07-28 10:58:57,891\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKgaF_RdaTYB",
        "outputId": "4b6506c6-afed-49ae-dd2a-c6d30451bc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on cuda using PyTorch 2.3.1+cu121 and Flower 1.9.0\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")\n",
        "def train(net, trainloader, epochs):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optim = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n",
        "            optim.zero_grad()\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6p0shiiaTYB"
      },
      "source": [
        "The code we have written so far is not specific to Federated Learning. Then, what are the key differences between Federated Learning and Centralised Training? If you could only pick you, probably you'd say:\n",
        "* Federated Learning is distributed -- the model is trained on-device by the participating clients.\n",
        "* Data remains private and is owned by a specific _client_ -- the data is never sent to the central server.\n",
        "\n",
        "The are several more differences. But the above two are the main ones to always consider and that are common to all flavours of Federated Learning (e.g. _cross-device_ or _cross-silo_). The remaining of this tutorial is going to focus in transforming the code we have written so far for the centralised setting and construct a Federated Learning pipeline using Flower and PyTorch.\n",
        "\n",
        "Let's begin! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-4xaxyJaTYC"
      },
      "source": [
        "## One Client, One Data Partition\n",
        "\n",
        "To start designing a Federated Learning pipeline we need to meet one of the key properties in FL: each client has its own data partition. To accomplish this with the MNIST dataset, we are going to generate N random partitions, where N is the total number of clients in our FL system.\n",
        "\n",
        "We can use [Flower Datasets](https://flower.ai/docs/datasets/) to effortlessly obtain an off-the-shelf partitioned dataset or partition one that isn't pre-partitioned. Let's choose MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cp0TfJHaTYC",
        "outputId": "92a09663-a1c5-46f6-f4ee-044e92ac9a91"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vaishnavi/.local/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for mnist contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mnist\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from flwr_datasets import FederatedDataset\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "\n",
        "# Let's set a simulation involving a total of 100 clients\n",
        "NUM_CLIENTS = 100\n",
        "\n",
        "# Download MNIST dataset and partition the \"train\" partition (so one can be assigned to each client)\n",
        "mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
        "# Let's keep the test set as is, and use it to evaluate the global model on the server\n",
        "centralized_testset = mnist_fds.load_split(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kcx7gkNaTYC"
      },
      "source": [
        "Let's create a function that returns a set of transforms to apply to our images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP4bJ-2UaTYC",
        "outputId": "fe9a07bc-52be-469a-9ec6-2e06fc3b5782"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    \"\"\"Get transformation for MNIST dataset\"\"\"\n",
        "\n",
        "    # transformation to convert images to tensors and apply normalization\n",
        "    transforms = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHZPfiyAaTYC"
      },
      "source": [
        "Let's next define how our FL clients will behave.\n",
        "\n",
        "## Defining a Flower Client\n",
        "\n",
        "You can think of a client in FL as an entity that owns some data and trains a model using this data. The caveat is that the model is being trained _collaboratively_ in Federation by multiple clients (sometimes up to hundreds of thousands) and, in most instances of FL, is sent by a central server.\n",
        "\n",
        "A Flower Client is a simple Python class with four distinct methods:\n",
        "\n",
        "* `fit()`: With this method, the client does on-device training for a number of epochs using its own data. At the end, the resulting model is sent back to the server for aggregation.\n",
        "\n",
        "* `evaluate()`: With this method, the server can evaluate the performance of the global model on the local validation set of a client. This can be used for instance when there is no centralised dataset on the server for validation/test. Also, this method can be use to asses the degree of personalisation of the model being federated.\n",
        "\n",
        "* `set_parameters()`: This method takes the parameters sent by the server and uses them to initialise the parameters of the local model that is ML framework specific (e.g. TF, Pytorch, etc).\n",
        "\n",
        "* `get_parameters()`: It extract the parameters from the local model and transforms them into a list of NumPy arrays. This ML framework-agnostic representation of the model will be sent to the server.\n",
        "\n",
        "Let's start by importing Flower!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyDFGmetaTYC"
      },
      "source": [
        "Now let's defice our Flower Client class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xAd77Whyb4cL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "def prune_model(model, pruning_method, structured=False, amount=0.1, dim=0, **kwargs):\n",
        "    # Collect the parameters to prune\n",
        "    parameters_to_prune = []\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
        "            if structured:\n",
        "                parameters_to_prune.append((module, 'weight'))\n",
        "            else:\n",
        "                parameters_to_prune.append((module, 'weight'))\n",
        "                if module.bias is not None:\n",
        "                    parameters_to_prune.append((module, 'bias'))\n",
        "\n",
        "    if structured:\n",
        "        # Apply global structured pruning\n",
        "        for module, param in parameters_to_prune:\n",
        "            prune.ln_structured(module, name=param, amount=amount, n=1, dim=dim, **kwargs)\n",
        "    else:\n",
        "        # Apply global unstructured pruning\n",
        "        prune.global_unstructured(\n",
        "            parameters_to_prune,\n",
        "            pruning_method=pruning_method,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    # Remove pruning reparameterization\n",
        "    for module, param in parameters_to_prune:\n",
        "        prune.remove(module, param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ShZkquPSlSqG"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from typing import cast\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "from flwr.common.typing import NDArray, NDArrays, Parameters\n",
        "\n",
        "\n",
        "def ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n",
        "    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n",
        "    tensors = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n",
        "    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n",
        "\n",
        "\n",
        "def sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
        "    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n",
        "    return [sparse_bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
        "\n",
        "\n",
        "def ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n",
        "    \"\"\"Serialize NumPy ndarray to bytes.\"\"\"\n",
        "    bytes_io = BytesIO()\n",
        "\n",
        "    if len(ndarray.shape) > 1:\n",
        "        # Flatten higher-dimensional array to 2D\n",
        "        original_shape = ndarray.shape\n",
        "        ndarray = ndarray.reshape(-1, ndarray.shape[-1])\n",
        "\n",
        "        # Convert ndarray to sparse matrix\n",
        "        sparse_matrix = scipy.sparse.csr_matrix(ndarray)\n",
        "\n",
        "        np.savez(\n",
        "            bytes_io,\n",
        "            data=sparse_matrix.data,\n",
        "            indices=sparse_matrix.indices,\n",
        "            indptr=sparse_matrix.indptr,\n",
        "            shape=sparse_matrix.shape,\n",
        "            original_shape=original_shape,  # Store original shape for reshaping\n",
        "            allow_pickle=False,\n",
        "        )\n",
        "    else:\n",
        "        np.save(bytes_io, ndarray, allow_pickle=False)\n",
        "    return bytes_io.getvalue()\n",
        "\n",
        "\n",
        "def sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n",
        "    \"\"\"Deserialize NumPy ndarray from bytes.\"\"\"\n",
        "    bytes_io = BytesIO(tensor)\n",
        "    loader = np.load(bytes_io, allow_pickle=False)\n",
        "\n",
        "    if \"indptr\" in loader:\n",
        "        # Convert sparse matrix back to ndarray\n",
        "        sparse_matrix = scipy.sparse.csr_matrix(\n",
        "            (loader[\"data\"], loader[\"indices\"], loader[\"indptr\"]),\n",
        "            shape=loader[\"shape\"]\n",
        "        )\n",
        "        ndarray_deserialized = sparse_matrix.toarray()\n",
        "\n",
        "        # Reshape back to original shape if needed\n",
        "        if \"original_shape\" in loader:\n",
        "            original_shape = loader[\"original_shape\"]\n",
        "            ndarray_deserialized = ndarray_deserialized.reshape(original_shape)\n",
        "    else:\n",
        "        ndarray_deserialized = loader\n",
        "    return cast(NDArray, ndarray_deserialized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Po5GZm9gnIu8"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple\n",
        "from collections import OrderedDict\n",
        "\n",
        "def get_parameters(model: torch.nn.ModuleList) -> List[np.ndarray]:\n",
        "    \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(model: torch.nn.ModuleList, params: List[np.ndarray]):\n",
        "    \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
        "    params_dict = zip(model.state_dict().keys(), params)\n",
        "    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wsD3zEwAlYdF"
      },
      "outputs": [],
      "source": [
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        ")\n",
        "\n",
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader, pruning_rate):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.pruning_rate = pruning_rate\n",
        "        self.new_model = net(num_classes=10)\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters = ndarrays_to_sparse_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        pruning_method = torch.nn.utils.prune.L1Unstructured\n",
        "        prune_model(self.net, pruning_method, structured=True, amount=self.pruning_rate, dim=0)\n",
        "\n",
        "        self.new_model.load_state_dict(self.net.state_dict())\n",
        "        ndarrays_updated = get_parameters(self.new_model)\n",
        "\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters_updated = ndarrays_to_sparse_parameters(ndarrays_updated)\n",
        "        # Save the sparse matrix to an .npz file\n",
        "        bytes_sent = sum(len(tensor) for tensor in parameters_updated.tensors)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={\"bytes sent\" : bytes_sent},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(loss),\n",
        "            num_examples=len(self.valloader),\n",
        "            metrics={\"accuracy\": float(accuracy), \"loss\" : float(loss)},\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxk51wtHvecb",
        "outputId": "aee32bfc-dd6a-460b-ff62-d480b616c288"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = ResNet12(num_classes=10)\n",
        "\n",
        "        # Determine device\n",
        "        model.to(DEVICE)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test(model, testloader)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AEHRR7zJl0dH"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import FitRes, MetricsAggregationFn, NDArrays, Parameters, Scalar\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
        "Setting `min_available_clients` lower than `min_fit_clients` or\n",
        "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
        "connected to the server. `min_available_clients` must be set to a value larger\n",
        "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FedSparse(FedAvg):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Custom FedAvg strategy with sparse matrices.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        fraction_fit : float, optional\n",
        "            Fraction of clients used during training. Defaults to 0.1.\n",
        "        fraction_evaluate : float, optional\n",
        "            Fraction of clients used during validation. Defaults to 0.1.\n",
        "        min_fit_clients : int, optional\n",
        "            Minimum number of clients used during training. Defaults to 2.\n",
        "        min_evaluate_clients : int, optional\n",
        "            Minimum number of clients used during validation. Defaults to 2.\n",
        "        min_available_clients : int, optional\n",
        "            Minimum number of total clients in the system. Defaults to 2.\n",
        "        evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
        "            Optional function used for validation. Defaults to None.\n",
        "        on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure training. Defaults to None.\n",
        "        on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure validation. Defaults to None.\n",
        "        accept_failures : bool, optional\n",
        "            Whether or not accept rounds containing failures. Defaults to True.\n",
        "        initial_parameters : Parameters, optional\n",
        "            Initial global model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_evaluate=fraction_evaluate,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        if self.evaluate_fn is None:\n",
        "            # No evaluation function provided\n",
        "            return None\n",
        "\n",
        "        # We deserialize using our custom method\n",
        "        parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n",
        "\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        return loss, metrics\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # We deserialize each of the results with our custom method\n",
        "        weights_results = [\n",
        "            (sparse_parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "\n",
        "        # We serialize the aggregated result using our custom method\n",
        "        parameters_aggregated = ndarrays_to_sparse_parameters(\n",
        "            aggregate(weights_results)\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-sFG-UYL1BWw"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
        "\n",
        "def aggregate_fit_metrics(metrics_list: List[Tuple[int, Dict[str, Scalar]]]) -> Dict[str, Scalar]:\n",
        "    \"\"\"Aggregate custom fit metrics from clients to calculate the average bytes sent.\n",
        "\n",
        "    Args:\n",
        "        metrics_list (List[Tuple[int, Dict[str, Scalar]]]): List of tuples, where each tuple\n",
        "        contains the number of examples and a dictionary of metrics from a client.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Scalar]: Aggregated metrics containing the average bytes sent.\n",
        "    \"\"\"\n",
        "    total_bytes_sent = 0\n",
        "    num_clients = len(metrics_list)\n",
        "\n",
        "    for _, metrics in metrics_list:\n",
        "        total_bytes_sent += metrics[\"bytes sent\"]\n",
        "\n",
        "    # Calculate the average bytes sent\n",
        "    average_bytes_sent = total_bytes_sent / num_clients if num_clients > 0 else 0\n",
        "\n",
        "    # Create the aggregated metrics dictionary\n",
        "    aggregated_metrics = {\n",
        "        \"bytes sent\": average_bytes_sent,\n",
        "    }\n",
        "\n",
        "    return aggregated_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Hy7uyFM-aTYD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=15, no round_timeout\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running simulation with pruning rate: 0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-28 11:06:07,031\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'memory': 866087508992.0, 'accelerator_type:RTX': 1.0, 'object_store_memory': 200000000000.0, 'node:10.8.0.3': 1.0, 'CPU': 40.0, 'GPU': 3.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "/tmp/ipykernel_1311801/3070706837.py:47: UserWarning: No `num_cpus` specified in `client_resources`. Using `num_cpus=1` for each client.\n",
            "  history = fl.simulation.start_simulation(\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_gpus': 1, 'num_cpus': 1}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 3 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 73, in _submit_job\n",
            "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 399, in get_client_result\n",
            "    return self._fetch_future_result(cid)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 280, in _fetch_future_result\n",
            "    res_cid, out_mssg, updated_context = ray.get(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
            "    return self._call(message, context)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
            "    out_message = handle_legacy_message_from_msgtype(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
            "    client = client_fn(str(message.metadata.partition_id))\n",
            "  File \"/tmp/ipykernel_1311801/3070706837.py\", line 42, in client_fn\n",
            "  File \"/tmp/ipykernel_1311801/3561780509.py\", line 19, in __init__\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "TypeError: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
            "    return self._call(message, context)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
            "    out_message = handle_legacy_message_from_msgtype(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
            "    client = client_fn(str(message.metadata.partition_id))\n",
            "  File \"/tmp/ipykernel_1311801/3070706837.py\", line 42, in client_fn\n",
            "  File \"/tmp/ipykernel_1311801/3561780509.py\", line 19, in __init__\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "TypeError: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
            "    return self._call(message, context)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
            "    out_message = handle_legacy_message_from_msgtype(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
            "    client = client_fn(str(message.metadata.partition_id))\n",
            "  File \"/tmp/ipykernel_1311801/3070706837.py\", line 42, in client_fn\n",
            "  File \"/tmp/ipykernel_1311801/3561780509.py\", line 19, in __init__\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "TypeError: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/app.py\", line 323, in start_simulation\n",
            "    hist = run_fl(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 490, in run_fl\n",
            "    hist, elapsed_time = server.fit(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 93, in fit\n",
            "    self.parameters = self._get_initial_parameters(server_round=0, timeout=timeout)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/server/server.py\", line 282, in _get_initial_parameters\n",
            "    get_parameters_res = random_client.get_parameters(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 148, in get_parameters\n",
            "    message_out = self._submit_job(message, timeout)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 87, in _submit_job\n",
            "    raise ex\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 73, in _submit_job\n",
            "    out_mssg, updated_context = self.actor_pool.get_client_result(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 399, in get_client_result\n",
            "    return self._fetch_future_result(cid)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 280, in _fetch_future_result\n",
            "    res_cid, out_mssg, updated_context = ray.get(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n",
            "    return self._call(message, context)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n",
            "    out_message = handle_legacy_message_from_msgtype(\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
            "    client = client_fn(str(message.metadata.partition_id))\n",
            "  File \"/tmp/ipykernel_1311801/3070706837.py\", line 42, in client_fn\n",
            "  File \"/tmp/ipykernel_1311801/3561780509.py\", line 19, in __init__\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "TypeError: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n",
            "  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
            "    raise ClientAppException(str(ex)) from ex\n",
            "flwr.client.client_app.ClientAppException: \n",
            "Exception ClientAppException occurred. Message: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n",
            "\n",
            "\u001b[91mERROR \u001b[0m:     Your simulation crashed :(. This could be because of several reasons. The most common are: \n",
            "\t > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: \n",
            "\t\t - You might be using a class attribute in your clients that hasn't been defined.\n",
            "\t\t - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).\n",
            "\t\t - The return types of methods in your clients/strategies might be incorrect.\n",
            "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
            "\t > All the actors in your pool crashed. This could be because: \n",
            "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_gpus': 1, 'num_cpus': 1} is not enough for your run). Use fewer concurrent actors. \n",
            "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_gpus': 1, 'num_cpus': 1}.\n",
            "Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Simulation crashed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRayTaskError(ClientAppException)\u001b[0m          Traceback (most recent call last)",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/app.py:323\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/server.py:490\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/server.py:93\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INIT]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating initial global parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/server.py:282\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    281\u001b[0m ins \u001b[38;5;241m=\u001b[39m GetParametersIns(config\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m--> 282\u001b[0m get_parameters_res \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_parameters_res\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m Code\u001b[38;5;241m.\u001b[39mOK:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:148\u001b[0m, in \u001b[0;36mRayActorClientProxy.get_parameters\u001b[0;34m(self, ins, timeout, group_id)\u001b[0m\n\u001b[1;32m    141\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_recordset_in_message(\n\u001b[1;32m    142\u001b[0m     recordset,\n\u001b[1;32m    143\u001b[0m     message_type\u001b[38;5;241m=\u001b[39mMessageTypeLegacy\u001b[38;5;241m.\u001b[39mGET_PARAMETERS,\n\u001b[1;32m    144\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    145\u001b[0m     group_id\u001b[38;5;241m=\u001b[39mgroup_id,\n\u001b[1;32m    146\u001b[0m )\n\u001b[0;32m--> 148\u001b[0m message_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recordset_to_getparametersres(message_out\u001b[38;5;241m.\u001b[39mcontent, keep_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:87\u001b[0m, in \u001b[0;36mRayActorClientProxy._submit_job\u001b[0;34m(self, message, timeout)\u001b[0m\n\u001b[1;32m     86\u001b[0m     log(ERROR, ex)\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_mssg\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:73\u001b[0m, in \u001b[0;36mRayActorClientProxy._submit_job\u001b[0;34m(self, message, timeout)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_pool\u001b[38;5;241m.\u001b[39msubmit_client_job(\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m a, a_fn, mssg, cid, state: a\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mremote(a_fn, mssg, cid, state),\n\u001b[1;32m     71\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapp_fn, message, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcid, state),\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m out_mssg, updated_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_client_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Update state\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py:399\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool.get_client_result\u001b[0;34m(self, cid, timeout)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Fetch result belonging to the VirtualClient calling this method\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# Return both result from tasks and (potentially) updated run context\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_future_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcid\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py:280\u001b[0m, in \u001b[0;36mVirtualClientEngineActorPool._fetch_future_result\u001b[0;34m(self, cid)\u001b[0m\n\u001b[1;32m    279\u001b[0m     future: ObjectRef[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cid_to_future[cid][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     res_cid, out_mssg, updated_context \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: (str, Message, Context)\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ray\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRayActorError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py:2667\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2666\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2667\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/worker.py:864\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mRayTaskError(ClientAppException)\u001b[0m: \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 98, in __call__\n    return self._call(message, context)\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/client_app.py\", line 81, in ffn\n    out_message = handle_legacy_message_from_msgtype(\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n    client = client_fn(str(message.metadata.partition_id))\n  File \"/tmp/ipykernel_1311801/3070706837.py\", line 42, in client_fn\n  File \"/tmp/ipykernel_1311801/3561780509.py\", line 19, in __init__\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\nTypeError: ResNet12.forward() got an unexpected keyword argument 'num_classes'\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=1321500, ip=10.8.0.3, actor_id=60c66f15fc9d7e27bc35fbd201000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7054e44bd840>)\n  File \"/home/vaishnavi/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n    raise ClientAppException(str(ex)) from ex\nflwr.client.client_app.ClientAppException: \nException ClientAppException occurred. Message: ResNet12.forward() got an unexpected keyword argument 'num_classes'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client_fn\n\u001b[1;32m     46\u001b[0m client_fn_callback \u001b[38;5;241m=\u001b[39m get_client_fn(mnist_fds)\n\u001b[0;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Collect the metrics\u001b[39;00m\n\u001b[1;32m     56\u001b[0m log_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpruning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: pruning_rate,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_loss_distributed\u001b[39m\u001b[38;5;124m\"\u001b[39m: history\u001b[38;5;241m.\u001b[39mlosses_distributed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_metrics_centralized\u001b[39m\u001b[38;5;124m\"\u001b[39m: history\u001b[38;5;241m.\u001b[39mmetrics_centralized\n\u001b[1;32m     63\u001b[0m }\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/app.py:359\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    329\u001b[0m     log(ERROR, traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[1;32m    330\u001b[0m     log(\n\u001b[1;32m    331\u001b[0m         ERROR,\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour simulation crashed :(. This could be because of several reasons. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         client_resources,\n\u001b[1;32m    358\u001b[0m     )\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation crashed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Stop time monitoring resources in cluster\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     f_stop\u001b[38;5;241m.\u001b[39mset()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Simulation crashed."
          ]
        }
      ],
      "source": [
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "strategy = FedSparse(evaluate_metrics_aggregation_fn = weighted_average,\n",
        "                     fit_metrics_aggregation_fn = aggregate_fit_metrics,\n",
        "                     evaluate_fn=get_evaluate_fn(centralized_testset))\n",
        "client_resources = None\n",
        "log_data = []\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "for pruning_rate in np.arange(0.1, 1.0, 0.1):\n",
        "    print(f\"Running simulation with pruning rate: {pruning_rate}\")\n",
        "    def get_client_fn(dataset: FederatedDataset):\n",
        "        \"\"\"Return a function to construct a client.\n",
        "\n",
        "        The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "        the strategy to participate.\n",
        "        \"\"\"\n",
        "\n",
        "        def client_fn(cid: str) -> FlowerClient:\n",
        "            \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "\n",
        "            # Let's get the partition corresponding to the i-th client\n",
        "            client_dataset = dataset.load_partition(int(cid), \"train\")\n",
        "\n",
        "            # Now let's split it into train (90%) and validation (10%)\n",
        "            client_dataset_splits = client_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "            trainset = client_dataset_splits[\"train\"]\n",
        "            valset = client_dataset_splits[\"test\"]\n",
        "\n",
        "            # Now we apply the transform to each batch.\n",
        "            trainloader = DataLoader(\n",
        "                trainset.with_transform(apply_transforms), batch_size=32, shuffle=True\n",
        "            )\n",
        "            valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=32)\n",
        "\n",
        "            # Create the model and move it to the correct device\n",
        "            net = ResNet12(num_classes=10).to(DEVICE)\n",
        "\n",
        "            # Create and return client\n",
        "            return FlowerClient(cid, net, trainloader, valloader, pruning_rate)\n",
        "\n",
        "        return client_fn\n",
        "\n",
        "    client_fn_callback = get_client_fn(mnist_fds)\n",
        "    history = fl.simulation.start_simulation(\n",
        "        strategy=strategy,\n",
        "        client_fn=client_fn_callback,\n",
        "        num_clients=2,\n",
        "        config=fl.server.ServerConfig(num_rounds=15),\n",
        "        client_resources=client_resources,\n",
        "    )\n",
        "\n",
        "    # Collect the metrics\n",
        "    log_entry = {\n",
        "        \"pruning_rate\": pruning_rate,\n",
        "        \"history_loss_distributed\": history.losses_distributed,\n",
        "        \"history_loss_centralized\": history.losses_centralized,\n",
        "        \"history_metrics_distributed_fit\": history.metrics_distributed_fit,\n",
        "        \"history_metrics_distributed_evaluate\": history.metrics_distributed,\n",
        "        \"history_metrics_centralized\": history.metrics_centralized\n",
        "    }\n",
        "    log_data.append(log_entry)\n",
        "\n",
        "# Write the collected log data to a JSON file\n",
        "with open('MNIST_ResNet12_Unstructured.json', 'w') as f:\n",
        "    json.dump(log_data, f, indent=4)\n",
        "\n",
        "print(\"Metrics logged\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
